{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "     -------------------------------------- 292.8/292.8 KB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\akshaya.srikanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.7.3)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\akshaya.srikanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\akshaya.srikanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.21.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\akshaya.srikanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\akshaya.srikanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.28.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\akshaya.srikanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\akshaya.srikanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\akshaya.srikanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\akshaya.srikanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\akshaya.srikanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\akshaya.srikanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\akshaya.srikanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six in c:\\users\\akshaya.srikanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relax Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import json\n",
    "import time\n",
    "import pylab\n",
    "from scipy import stats\n",
    "from datetime import date\n",
    "import datetime as dt\n",
    "\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is available as two attached CSV files:\n",
    "\n",
    "    takehome_user_engagement.csv\n",
    "    takehome_users.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data has the following two tables:\n",
    "\n",
    "\n",
    "**1.  User table **\n",
    "----\n",
    "- ( \"takehome_users\" ) with data on 12,000 users who signed up for the product in the last two years. \n",
    "\n",
    "This table includes:\n",
    "\n",
    "    ● name: the user's name\n",
    "\n",
    "    ● object_id: the user's id\n",
    "\n",
    "    ● email: email address\n",
    "\n",
    "    ● creation_source: how their account was created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes on one of 5 values:\n",
    "\n",
    "PERSONAL_PROJECTS: invited to join another user's\n",
    "personal workspace\n",
    "- GUEST_INVITE: invited to an organization as a guest\n",
    "(limited permissions)\n",
    "- ORG_INVITE: invited to an organization (as a full member)\n",
    "- SIGNUP: signed up via the website\n",
    "- SIGNUP_GOOGLE_AUTH: signed up using Google\n",
    "Authentication (using a Google email account for their login id)\n",
    "\n",
    "    a. creation_time: when they created their account\n",
    "\n",
    "    b. last_session_creation_time: unix timestamp of last login\n",
    "\n",
    "    c. opted_in_to_mailing_list: whether they have opted into receiving marketing emails\n",
    "\n",
    "    d. enabled_for_marketing_drip: whether they are on the regular marketing email drip\n",
    "\n",
    "    e. org_id: the organization (group of users) they belong to\n",
    "\n",
    "    f. invited_by_user_id: which user invited them to join (if applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>creation_source</th>\n",
       "      <th>last_session_creation_time</th>\n",
       "      <th>opted_in_to_mailing_list</th>\n",
       "      <th>enabled_for_marketing_drip</th>\n",
       "      <th>org_id</th>\n",
       "      <th>invited_by_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-22 03:53:30</td>\n",
       "      <td>Clausen August</td>\n",
       "      <td>AugustCClausen@yahoo.com</td>\n",
       "      <td>GUEST_INVITE</td>\n",
       "      <td>1.398139e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-11-15 03:45:04</td>\n",
       "      <td>Poole Matthew</td>\n",
       "      <td>MatthewPoole@gustr.com</td>\n",
       "      <td>ORG_INVITE</td>\n",
       "      <td>1.396238e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-03-19 23:14:52</td>\n",
       "      <td>Bottrill Mitchell</td>\n",
       "      <td>MitchellBottrill@gustr.com</td>\n",
       "      <td>ORG_INVITE</td>\n",
       "      <td>1.363735e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>1525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-05-21 08:09:28</td>\n",
       "      <td>Clausen Nicklas</td>\n",
       "      <td>NicklasSClausen@yahoo.com</td>\n",
       "      <td>GUEST_INVITE</td>\n",
       "      <td>1.369210e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013-01-17 10:14:20</td>\n",
       "      <td>Raw Grace</td>\n",
       "      <td>GraceRaw@yahoo.com</td>\n",
       "      <td>GUEST_INVITE</td>\n",
       "      <td>1.358850e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>5240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id        creation_time               name  \\\n",
       "0          1  2014-04-22 03:53:30     Clausen August   \n",
       "1          2  2013-11-15 03:45:04      Poole Matthew   \n",
       "2          3  2013-03-19 23:14:52  Bottrill Mitchell   \n",
       "3          4  2013-05-21 08:09:28    Clausen Nicklas   \n",
       "4          5  2013-01-17 10:14:20          Raw Grace   \n",
       "\n",
       "                        email creation_source  last_session_creation_time  \\\n",
       "0    AugustCClausen@yahoo.com    GUEST_INVITE                1.398139e+09   \n",
       "1      MatthewPoole@gustr.com      ORG_INVITE                1.396238e+09   \n",
       "2  MitchellBottrill@gustr.com      ORG_INVITE                1.363735e+09   \n",
       "3   NicklasSClausen@yahoo.com    GUEST_INVITE                1.369210e+09   \n",
       "4          GraceRaw@yahoo.com    GUEST_INVITE                1.358850e+09   \n",
       "\n",
       "   opted_in_to_mailing_list  enabled_for_marketing_drip  org_id  \\\n",
       "0                         1                           0      11   \n",
       "1                         0                           0       1   \n",
       "2                         0                           0      94   \n",
       "3                         0                           0       1   \n",
       "4                         0                           0     193   \n",
       "\n",
       "   invited_by_user_id  \n",
       "0             10803.0  \n",
       "1               316.0  \n",
       "2              1525.0  \n",
       "3              5151.0  \n",
       "4              5240.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "takehome_users = pd.read_csv('takehome_users.csv',encoding='ISO-8859-1')\n",
    "takehome_users.head()#used encoding to remediate the non unicode error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12000 entries, 0 to 11999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   object_id                   12000 non-null  int64  \n",
      " 1   creation_time               12000 non-null  object \n",
      " 2   name                        12000 non-null  object \n",
      " 3   email                       12000 non-null  object \n",
      " 4   creation_source             12000 non-null  object \n",
      " 5   last_session_creation_time  8823 non-null   float64\n",
      " 6   opted_in_to_mailing_list    12000 non-null  int64  \n",
      " 7   enabled_for_marketing_drip  12000 non-null  int64  \n",
      " 8   org_id                      12000 non-null  int64  \n",
      " 9   invited_by_user_id          6417 non-null   float64\n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "takehome_users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Usage summary table **\n",
    "- ( \"takehome_user_engagement\" ) that has a row for each day that a user logged into the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>visited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-22 03:53:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-15 03:45:04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-29 03:45:04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-09 03:45:04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-25 03:45:04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_stamp  user_id  visited\n",
       "0  2014-04-22 03:53:30        1        1\n",
       "1  2013-11-15 03:45:04        2        1\n",
       "2  2013-11-29 03:45:04        2        1\n",
       "3  2013-12-09 03:45:04        2        1\n",
       "4  2013-12-25 03:45:04        2        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "takehome_user_engagement=pd.read_csv('takehome_user_engagement.csv')\n",
    "takehome_user_engagement.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 207917 entries, 0 to 207916\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   time_stamp  207917 non-null  object\n",
      " 1   user_id     207917 non-null  int64 \n",
      " 2   visited     207917 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "takehome_user_engagement.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project \n",
    "----\n",
    "Defining an \"adopted user\" as a user who has logged into the product on three separate\n",
    "days in at least one seven day period, identify which factors predict future user\n",
    "adoption.\n",
    "\n",
    "We suggest spending 1-2 hours on this, but you're welcome to spend more or less.\n",
    "\n",
    "1. Please send us a brief write-up of your findings (the more concise, the better no more than one page), along with any summary tables, graphs, code, or queries that can help us understand your approach. \n",
    "\n",
    "2. Please note any factors you considered or investigation you did, even if they did not pan out. Feel free to identify any further research or data you think would be valuable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thoughts:**\n",
    "\n",
    "**takehome_users: **\n",
    "\n",
    "*Need to make sure the date/time variables are coded as such. One of the column titles is inconsistent with the data description. Certainly not all of the data is going to be useful, certainly not the personal details of the users.*\n",
    "\n",
    "**takehome_user_engagement:** \n",
    "\n",
    "*The time stamp is going to need to be changed*\n",
    "\n",
    "    a. I'm already thinking that the data are going to need to be merged between the user_engagement dataset and the user dataset.\n",
    "    b. Since the question mentioned seven day units I will need to code weekly units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning/Prep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions I commonly use to deal with date/time values\n",
    "def get_date_int(df, column):\n",
    "    '''\n",
    "    This handy function parses year,month,week,day.\n",
    "    '''\n",
    "    year = df[column].dt.year\n",
    "    month = df[column].dt.month\n",
    "    day = df[column].dt.day\n",
    "    return year, month, day\n",
    "\n",
    "def get_week(x): \n",
    "    return x.isocalendar()\n",
    "\n",
    "def get_iso_date_int(df,column):\n",
    "    '''\n",
    "    With time coded as iso (year,week,day) this seperates those time periods.\n",
    "    '''\n",
    "    temp_df=pd.DataFrame(df[column].tolist(), index=df.index)\n",
    "    year,week,day=temp_df[0],temp_df[1],temp_df[2]\n",
    "    return year,week,day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_time</th>\n",
       "      <th>creation_source</th>\n",
       "      <th>last_session_creation_time</th>\n",
       "      <th>opted_in_to_mailing_list</th>\n",
       "      <th>enabled_for_marketing_drip</th>\n",
       "      <th>org_id</th>\n",
       "      <th>invited_by_user_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-22 03:53:30</td>\n",
       "      <td>GUEST_INVITE</td>\n",
       "      <td>1970-01-01 00:00:01.398138810</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10803.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-15 03:45:04</td>\n",
       "      <td>ORG_INVITE</td>\n",
       "      <td>1970-01-01 00:00:01.396237504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>316.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-19 23:14:52</td>\n",
       "      <td>ORG_INVITE</td>\n",
       "      <td>1970-01-01 00:00:01.363734892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-05-21 08:09:28</td>\n",
       "      <td>GUEST_INVITE</td>\n",
       "      <td>1970-01-01 00:00:01.369210168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5151.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-17 10:14:20</td>\n",
       "      <td>GUEST_INVITE</td>\n",
       "      <td>1970-01-01 00:00:01.358849660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>5240.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        creation_time creation_source    last_session_creation_time  \\\n",
       "0 2014-04-22 03:53:30    GUEST_INVITE 1970-01-01 00:00:01.398138810   \n",
       "1 2013-11-15 03:45:04      ORG_INVITE 1970-01-01 00:00:01.396237504   \n",
       "2 2013-03-19 23:14:52      ORG_INVITE 1970-01-01 00:00:01.363734892   \n",
       "3 2013-05-21 08:09:28    GUEST_INVITE 1970-01-01 00:00:01.369210168   \n",
       "4 2013-01-17 10:14:20    GUEST_INVITE 1970-01-01 00:00:01.358849660   \n",
       "\n",
       "   opted_in_to_mailing_list  enabled_for_marketing_drip  org_id  \\\n",
       "0                         1                           0      11   \n",
       "1                         0                           0       1   \n",
       "2                         0                           0      94   \n",
       "3                         0                           0       1   \n",
       "4                         0                           0     193   \n",
       "\n",
       "   invited_by_user_id  user_id  \n",
       "0             10803.0        1  \n",
       "1               316.0        2  \n",
       "2              1525.0        3  \n",
       "3              5151.0        4  \n",
       "4              5240.0        5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "takehome_users = pd.read_csv('takehome_users.csv',encoding='ISO-8859-1')\n",
    "#code creation_time,last_session_time as date/time\n",
    "takehome_users.creation_time = pd.to_datetime(takehome_users['creation_time'])\n",
    "takehome_users.last_session_creation_time = pd.to_datetime(takehome_users['last_session_creation_time'])\n",
    "#change column heading\n",
    "takehome_users['user_id'] = takehome_users['object_id']\n",
    "#drop original column\n",
    "takehome_users.drop('object_id', axis=1, inplace=True)\n",
    "#drop private information\n",
    "takehome_users.drop(['name', 'email'], axis=1, inplace=True)\n",
    "\n",
    "takehome_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12000 entries, 0 to 11999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   creation_time               12000 non-null  datetime64[ns]\n",
      " 1   creation_source             12000 non-null  object        \n",
      " 2   last_session_creation_time  8823 non-null   datetime64[ns]\n",
      " 3   opted_in_to_mailing_list    12000 non-null  int64         \n",
      " 4   enabled_for_marketing_drip  12000 non-null  int64         \n",
      " 5   org_id                      12000 non-null  int64         \n",
      " 6   invited_by_user_id          6417 non-null   float64       \n",
      " 7   user_id                     12000 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(1), int64(4), object(1)\n",
      "memory usage: 750.1+ KB\n"
     ]
    }
   ],
   "source": [
    "takehome_users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make user engagement time_stamp into date/time\n",
    "takehome_user_engagement['time_stamp'] = pd.to_datetime(takehome_user_engagement['time_stamp'])\n",
    "#Make a weekly unit for time stamp\n",
    "takehome_user_engagement['week_time_stamp']=takehome_user_engagement['time_stamp'].apply(get_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First user engagement timestamp: 2012-05-31 08:20:06\n",
      "Last user engagement timestamp: 2014-06-06 14:58:50\n"
     ]
    }
   ],
   "source": [
    "#This is useful to know so we know where the start and finish of the trial exists\n",
    "print('First user engagement timestamp:',min(takehome_user_engagement.time_stamp))\n",
    "print('Last user engagement timestamp:',max(takehome_user_engagement.time_stamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Year,Month,Week,and Day units. To be fair I would be doing this regardless of use,\n",
    "# since I know I will be working with time its useful to have options for working with the data\n",
    "year, month, day=get_date_int(takehome_user_engagement, 'time_stamp')\n",
    "takehome_user_engagement['year'],takehome_user_engagement['month'],takehome_user_engagement['day']=year,month,day\n",
    "takehome_user_engagement['week']=takehome_user_engagement['time_stamp'].dt.isocalendar().week\n",
    "#Make year and week, So if we are dealing with 52 week units then I want year to make it individual unit of time\n",
    "iso_year,iso_week,iso_day=get_iso_date_int(takehome_user_engagement,'week_time_stamp')\n",
    "takehome_user_engagement['year_week']=list(zip(iso_year,iso_week))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining an \"adopted user\" as a user who has logged into the product on three separate\n",
    "days in at least one seven day period, identify which factors predict future user\n",
    "adoption.\n",
    "\n",
    "    a. After playing with the data and thinking about the problem I decided the easiest time scale to use is the year/week units I created. I minimized the data to values I will need to solve the problem of 'adopted users'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "takehome_user_engagement=takehome_user_engagement.sort_values(['time_stamp','user_id'],ascending=True)\n",
    "takehome_user_engagement=takehome_user_engagement[['user_id','visited','day','year_week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I tried to do this without using any for loops.... \n",
    "#   - I still think I can but for parsimony I decided just to use a single for loop\n",
    "# What I got is a label dictionary for user_id and adopted_engagement_index which,\n",
    "# I define as the number of logins of user attempts in a week that are,\n",
    "#    - seperate daily events (greater than 3 days).\n",
    "\n",
    "# Label dictionary\n",
    "adopted_user_dict={}\n",
    "#number of year/week units\n",
    "weeks=takehome_user_engagement.year_week\n",
    "#individual user ids\n",
    "user_ids=list(set(takehome_user_engagement['user_id']))\n",
    "#loop over user ids\n",
    "for i in range(len(user_ids)):\n",
    "    user_id=user_ids[i]\n",
    "    #dataframe for specific user that has duplicate records by week\n",
    "    reduced_df=takehome_user_engagement[(takehome_user_engagement['user_id']==user_id)&(weeks.isin(weeks[weeks.duplicated()]))]\n",
    "    #count the number of duplicate 'day' records of weeks if greater than 2 keep\n",
    "    week_counts=reduced_df.year_week.value_counts()[reduced_df.year_week.value_counts()>2]\n",
    "    three_logins=reduced_df[reduced_df.year_week.isin(list(week_counts.index))]\n",
    "    #remove duplicates of 3 day events within week\n",
    "    three_logins=three_logins[~three_logins.duplicated()]\n",
    "    #code user id and number of 3 day events\n",
    "    adopted_user_dict[str(user_id)]=len(three_logins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHAY~1.SRI\\AppData\\Local\\Temp/ipykernel_15952/2779594177.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#apply the label dictionary to user ids coded to the column (engagement_index)\n",
    "takehome_user_engagement['engagement_index']=takehome_user_engagement['user_id'].apply(lambda x: adopted_user_dict[str(x)])\n",
    "#Code engagement_index as boolean values, which will be the adopted_user records\n",
    "takehome_user_engagement['adopted_user']=0\n",
    "takehome_user_engagement['adopted_user'][takehome_user_engagement['engagement_index']>0]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*After coding for 'adopted_users' I am left with 1445 users who have logged in on 3 seperate days within a seven day period.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of adopted users: 1445\n"
     ]
    }
   ],
   "source": [
    "adopted_count=takehome_user_engagement[['user_id','adopted_user']][takehome_user_engagement['adopted_user']==1].groupby('user_id').count()\n",
    "print('Number of adopted users:',len(adopted_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Narrow down the dataset for merging\n",
    "adopted=takehome_user_engagement[['user_id','adopted_user']]\n",
    "#Merge the adopted user info to users dataframe\n",
    "adopted_users = pd.merge(takehome_users, adopted, on='user_id', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*After merging the 'adopted_users' to the larger 'users' dataset I will modify the time units to useful units, once again I am not certain which time units I will need but is a thing I typically do so I have options for different scales of time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_year, creation_month, creation_day=get_date_int(adopted_users, 'creation_time')\n",
    "last_session_year, last_session_month, last_session_day=get_date_int(adopted_users, 'last_session_creation_time')\n",
    "adopted_users['creation_year'],adopted_users['creation_month'],adopted_users['creation_day']=creation_year, creation_month, creation_day\n",
    "adopted_users['last_session_year'],adopted_users['last_session_month'],adopted_users['last_session_day']=last_session_year, last_session_month, last_session_day\n",
    "adopted_users.drop(['creation_time', 'last_session_creation_time', 'user_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in the missing values with something (zero) I think if I had more time I would spend it looking at what would be the best imputation method (mode,median,mean, or zero fill)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adopted_users.last_session_day.fillna(0, inplace=True)\n",
    "adopted_users.last_session_month.fillna(0, inplace=True)\n",
    "adopted_users.last_session_year.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Label encoder for the string values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\AKSHAY~1.SRI\\AppData\\Local\\Temp/ipykernel_15952/256814530.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0madopted_users\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'creation_source'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madopted_users\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'creation_source'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "adopted_users['creation_source']=le.fit_transform(adopted_users['creation_source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create binary for the invited users *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adopted_users['invited'] = np.where(adopted_users['invited_by_user_id'].isnull(), 1, 0)\n",
    "adopted_users.drop('invited_by_user_id', axis=1, inplace=True)\n",
    "#Fill in the missings\n",
    "adopted_users=adopted_users.fillna(0)\n",
    "#Create column labels for output\n",
    "col_names=list(pd.Series(adopted_users.columns)[pd.Series(adopted_users.columns)!='adopted_user'])\n",
    "#Code as arrays\n",
    "X=adopted_users[list(pd.Series(adopted_users.columns)[pd.Series(adopted_users.columns)!='adopted_user'])].values\n",
    "y=adopted_users['adopted_user'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,random_state=3)\n",
    "print('Train size:',(len(X_train)/len(X))*100)\n",
    "print('Train observations:',(len(X_train)))\n",
    "print('Test size:',(len(X_test)/len(X))*100)\n",
    "print('Test observations:',(len(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Fit Random Forest Model\n",
    " ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20,random_state=0,criterion='gini', class_weight='balanced')\n",
    "\n",
    "clf.fit(X_train, y_train.ravel())\n",
    "Accuracy=clf.score(X_train, y_train.ravel())\n",
    "print('Accuracy:',Accuracy,'\\n')\n",
    "\n",
    "importFeature = clf.feature_importances_\n",
    "feature_importances=pd.DataFrame([importFeature])\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],axis=0)\n",
    "indices = np.argsort(importFeature)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importFeature[indices],color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "feature_importances=pd.DataFrame(pd.Series(col_names)[indices])\n",
    "feature_importances['importance']=np.sort(importFeature)[::-1]\n",
    "feature_importances.columns=['features','importance']\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although I got an accuracy of 99% I believe the model is falacious to a degree since it is seperating the data too well, either because the model is overfitting, or because the data is improperly prepared. Regardless of the reasoning we can see the most important features for predicting the 'Adopted Users' in the dataset to be the group of users assigned the organization id (org_id), the time the id was created, and the last login time. This means that users from particular cohorts are more likely to login more frequently than others for som unspecified reason. I think the data needs more features that describe user details in order to get a proper model for describing user adoption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
